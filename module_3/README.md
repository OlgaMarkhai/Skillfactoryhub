# Итоговая работа Мархай Ольги по Проекту 3. О вкусной и здоровой пище.  

## Оглавление  
[1. Описание модуля](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Описание-модуля)  
[2. Какой кейс решаем?](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Какой-кейс-решаем?)  
[3. Краткая информация о данных](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Краткая-информация-о-данных)  
[4. Полное описание задания с kaggle](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Полное-описание-задания-с-kaggle)  
[5. Краткое описание проделанной работы](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Краткое-описание-проделанной-работы)  
[6. Результат](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Результат)  


### Описание модуля  
Что вы получите в результате работы?  
- создадите свою первую модель, основанную на алгоритмах машинного обучения.
- примете участие в соревновании на Kaggle.
- поймете как правильно "готовить" данные, чтобы ваша модель работала лучше.  

***Чем мы будем заниматься?***  
В этом модуле вы попробуете решить свой первый настоящий кейс и создадите первую модель, использующую алгоритмы машинного обучения.  
Не пугайтесь, вам не придётся совершать академический подвиг и изучать машинное обучение в экстремально короткие сроки! На самом деле код для создания и обучения модели мы вам предоставим в готовом виде, и этот код будет довольно простым: в нём не будет предусмотрен подбор параметров и тонкая настройка модели (всему этому вы научитесь позже, в курсе по ML). Пока ваша задача будет состоять в том, чтобы качественно подготовить данные для обучения модели. Скоро вы убедитесь, что тщательная очистка данных и генерация новых признаков (Feature Engineering ) способны повысить точность модели в 2 и более раз, и владение этими навыками играют в машинном обучении не меньшую роль, чем умение выбрать алгоритм и настроить модель.  
Итак, факт остается фактом: свою первую модель вы создадите уже через пару недель, а после этого, в следующие две недели, используете свои наработки для участия в первом в вашей жизни соревновании на платформе Kaggle.com  
:arrow_up:[к оглавлению](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Оглавление)

### Какой кейс решаем?
Представьте, что Вы работаете DS в компании TripAdvisor. Одна из проблем TripAdvisorа — это нечестные рестораны, которые накручивают себе рейтинг. Одним из способов нахождения таких ресторанов, является построение модели, которая предсказывает рейтинг ресторана. Если предсказания модели сильно отличаются от фактического результата, то, возможно, ресторан играет нечестно, и его стоит проверить.

### Краткая информация о данных
В этом модуле вы будете работать с датасетом, содержащим сведения о 40 000 ресторанах Европы, а модель, которую вы будете обучать, должна будет предсказывать рейтинг ресторана по данным сайта TripAdvisor на основе имеющихся в датасете данных.  
Датасет представлен в репозитории в папке [**data** ](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/data)  

:arrow_up:[к оглавлению](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Оглавление)

### Полное описание задания с kaggle  
В этом соревновании вам будет предложен датасет, содержащий сведения о ресторанах. С помощью имеющего в вашем распоряжении кода, вам необходимо создать модель, использующую алгоритм RandomForestRegression, которая будет прогнозировать рейтинг ресторана по версии TripAdvidor.  
Для победы в конкурсе вам необходимо качественно очистить датасет, подобрать подходящие значения для заполнения пропусков и создать новые признаки на основе той информации, которую вы сможете извлечь из имеющихся в вашем распоряжении данных.  
Условия соревнования:  
- Все участники должны использовать один и тот же алгоритм с параметрами, заданными по умолчанию.  
- Разрешено использовать внешние данные.  
- Решения буду проверяться преподавателями на их адекватность и воспроизводимость.  

Во вкладке Notebooks этого соревнования для Вас доступно Базовое решение (Baseline)
:arrow_up:[к оглавлению](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Оглавление)


### Краткое описание проделанной работы
Общие принципы оформления ноутбука и реализации проекта:  
- повторяющие и громозкие операции вынесены в отдельный модуль  
- громозкие блока кода относящие к теме Юнита не выносились в модуль, чтобы можно было сразу оценить их эффективность и проверить корректность применения  
- некоторые прокомментированные ранее однотипные блоки кода, не комментировались повторно
- блоки кода, который был выполнил ранее и сгенерил промежуточный результат был закомментирован
- парсинг намеренно не использовался в данном проекте, чтобы более детально изучить подготовку данных для модели Случайный лес и специфику ее работы  
- некоторая избыточность обработки данных (стандартизация, метод главных компонент и полиномиальный принцип генерации признаков и т.п.) была продиктована желанием закрепить на практике пройденный материал Юнита
- интересные инсайты, которые не были проработаны до конца, обернуты в \<details>

Этапы работ и главные моменты их реализации:
1. Импорт данных  
2. Предварительный анализ данных (pandas_profiling)  
3. Детальный анализ по переменным  
  3.1. Restaurant_id  
  3.2. Cuisine Style (использовалась распаковка вложенных списоков с помощью .extend и collections.Counter, которая оказалась быстрее других способов в том числе специальной библиотеки ast)  
  3.3. Price Range  
  3.4. Number of Reviews  
  3.5. Reviews (работа с датами с помощью регулярных выражений и библиотеки datetime, погружение в историю компании TrippAdvisor для анализа выбросов по порогу)  
  3.6. ID_TA  
  3.7. URL_TA  
  3.8. City (создан новый критерий code_City с помощь интелектуальной кодировки LabelEncoder из библиотеки sklearn, сгенерированны новые критерии кол-во населения и страны из внешних источников)  
  3.9. Ranking (с помощью визуализации срезов данных критерия были сгенерированны новый признаки, которые вошли топ по важности для модели)  
4. Построчная верификация первых двух строк  
5. Удаление нечисловых критериев  
6. Стандартизация и заполнение пропусков (StandardScaler из sklearn.preprocessing)  
7. Разбивка датасета на тренировочный и тестовый  
8. Обучение модели, генерация результата и сравнивнение с тестом (train_test_split, RandomForestRegressor, MAE, metrics из sklearn)  
9. Проверка корреляцию важных переменных и применение метода главных компонент (PCA) (model.feature_importances_)  
10. Генерация новых критериев с помощью полиномиального метода  
11. Тестирование оптимального набора критериев  
12. Submission  
:arrow_up:[к оглавлению](https://github.com/OlgaMarkhai/Skillfactoryhub/edit/main/module_3/README.md#Оглавление)


### Результат  
- score - 0.20351 
